---
title: 【深度学习基础】2.线性神经网络 1.线性回归的基础实现
date: 2023-06-26 00:00:00 +0800
img_path: /assets/img/md
categories: [记录, 深度学习基础]
tags: [记录, 基础学习, Pytorch,深度学习]     # TAG names should always be lowercase
---

## 1. 数据集生成

全文依托于李沐老师的《动手学深度学习》一书，旨在对学习过程中的一些知识点作一点个人的记录和总结，仅供个人温习所用，原教程链接[动手学深度学习2.0](https://zh-v2.d2l.ai/)


```python
%matplotlib inline
import random
import torch
import husky
```

我们定义一个函数来生成数据集。该函数返回一个元组，其中包含特征矩阵`X`和标签向量`y`。特征矩阵`X`的每一行都包含一个二维数据样本，标签向量`y`的每一行都包含一维标签值（一个标量）：


```python
def synthetic_data(w, b, num_examples):  #@save
    """生成y=Xw+b+噪声"""
    X = torch.normal(0, 1, (num_examples, len(w)))#num_examples行，len(w)列,均值0，标准差1
    y = torch.matmul(X, w) + b#matmul()矩阵相乘
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))#-1表示自动推断维度大小，此处限制仅一列

true_w = torch.tensor([2, -3.4])#真实权重
true_b = 4.2#真实偏差
features, labels = synthetic_data(true_w, true_b, 1000)
```

检验其中一组数据


```python
print('features:', features[0],'\nlabel:', labels[0])
```

    features: tensor([0.1035, 0.1373]) 
    label: tensor([3.9464])
    

绘制出第二个特征`X[:, 1]`和标签`y`之间的散点图，以观察两者之间的线性关系。


```python
husky.husky_pic.set_figsize()
husky.husky_pic.plt.scatter(features[:, 1].detach().numpy(), labels.detach().numpy(),1)
```




    <matplotlib.collections.PathCollection at 0x1dcbec769d0>




    
![png](2.线性神经网络%201.线性回归的基础实现_8_1.png)
    


## 2. 数据集读取

为了方便训练模型，我们定义一个函数`data_iter`，它每次返回`batch_size`（批量大小）个随机样本的特征和标签，这样每次训练时，我们都可以读取一小批量的数据用来更新我们的模型


```python
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))#生成0到num_examples-1的列表
    # 这些样本是随机读取的，没有特定的顺序
    random.shuffle(indices)#随机打乱indices
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)])#要留意最后几个批次可能不足一个batch
        yield features[batch_indices], labels[batch_indices]
        #yield返回的是一个生成器，是一个可迭代的对象，可以使用for循环进行迭代，每次迭代都会返回一个值
        #用在这里可以返回一个batch的数据而不是单个索引对应的数据
```

干说可能不是很好理解，我们来看一下具体的使用


```python
batch_size = 10

for X, y in data_iter(batch_size, features, labels):
    print(X, '\n', y)
    break
```

    tensor([[-2.8120, -0.2687],
            [ 1.3048, -1.7154],
            [ 0.0150, -0.2502],
            [-0.7700, -1.0600],
            [-1.1146, -1.0983],
            [-0.1229,  0.0316],
            [-0.3652, -0.7178],
            [ 0.8849,  0.5101],
            [ 0.9265, -0.8909],
            [ 0.9254, -1.1303]]) 
     tensor([[-0.5112],
            [12.6355],
            [ 5.1007],
            [ 6.2619],
            [ 5.6978],
            [ 3.8596],
            [ 5.9003],
            [ 4.2197],
            [ 9.0853],
            [ 9.8842]])
    

以上代码仅为示例，执行效率较低，实际上pytorch等框架内置的迭代器更加高效，直接使用即可

## 3. 初始化模型参数

在我们开始用小批量随机梯度下降优化我们的模型参数之前， 我们需要先有一些参数。 在下面的代码中，我们通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重， 并将偏置初始化为0，在这之后我们将它们附加的梯度来迭代参数


```python
w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)
```

## 4. 模型定义

线性回归的计算表达式较为简单，我们只需要定义一个包含从输入到输出的计算表达式的网络，即$y = Xw + b$。


```python
def linreg(X, w, b):#@save
    """线性回归模型"""
    return torch.matmul(X, w) + b
```

## 5. 损失函数定义

这里我们使用平方损失函数来定义线性回归的损失。在实现中，我们需要把真实值`y`变形成预测值`y_hat`的形状。以下函数返回的结果也将和`y_hat`的形状相同。


```python
def squared_loss(y_hat, y):#@save
    """均方损失"""
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2
```

## 6. 优化算法

我们这里采用小批量的随机梯度下降算法来优化模型的损失函数。该函数接受模型参数集合、学习速率和批量大小作为输入。每 一步更新的大小由学习速率lr决定。 因为我们计算的损失是一个批量样本的总和，所以我们用批量大小（batch_size） 来规范化步长，这样步长大小就不会取决于我们对批量大小的选择。


```python
def sgd(params, lr, batch_size):#@save
    """小批量随机梯度下降"""
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()
```

## 7. 模型训练

在每次迭代中，我们读取一小批量训练样本，并通过我们的模型来获得一组预测。 计算完损失后，我们开始反向传播，存储每个参数的梯度。 最后，我们调用优化算法sgd来更新模型参数。


```python
lr = 0.03
num_epochs = 3
net = linreg
loss = squared_loss

for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        l = loss(net(X, w, b), y)  # X和y的小批量损失
        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，
        # 并以此计算关于[w,b]的梯度
        l.sum().backward()
        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数
    with torch.no_grad():#不计算梯度
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
```

    epoch 1, loss 0.027867
    epoch 2, loss 0.000104
    epoch 3, loss 0.000056
    

完成训练后让我们来计算一下训练后的参数与真实参数的误差大小


```python
print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')
print(f'b的估计误差: {true_b - b}')
```

    w的估计误差: tensor([ 0.0006, -0.0005], grad_fn=<SubBackward0>)
    b的估计误差: tensor([-8.0585e-05], grad_fn=<RsubBackward1>)
    

来让我们看看我们最后学到的模型参数是什么


```python
print(f"y={w.detach().numpy()}x+{b.detach().numpy()}")
```

    y=[[ 1.9993758]
     [-3.3995204]]x+[4.2000804]
    
